# ðŸ“Š Rapport dâ€™Analyse Statistique & ACP â€” Wine Quality (White)

## **1. PrÃ©sentation gÃ©nÃ©rale de la base de donnÃ©es**

La base de donnÃ©es **Wine Quality - White** contient des mesures physicoâ€‘chimiques de **4 898 vins blancs portugais** ainsi que leur **note de qualitÃ©** attribuÃ©e par des experts (de 0 Ã  10). Ces donnÃ©es proviennent dâ€™une Ã©tude du *Vinho Verde*, couramment utilisÃ©e en data science.

### **Variables prÃ©sentes dans la BDD :**

| Variable             | Description                           |
| -------------------- | ------------------------------------- |
| fixed acidity        | AciditÃ© fixe (g(tartaric acid)/dmÂ³)   |
| volatile acidity     | AciditÃ© volatile (g(acetic acid)/dmÂ³) |
| citric acid          | Acide citrique (g/dmÂ³)                |
| residual sugar       | Sucre rÃ©siduel (g/dmÂ³)                |
| chlorides            | Chlore (g(sodium chloride)/dmÂ³)       |
| free sulfur dioxide  | Soufre libre (mg/dmÂ³)                 |
| total sulfur dioxide | Soufre total (mg/dmÂ³)                 |
| density              | DensitÃ© du vin                        |
| pH                   | AciditÃ© pH                            |
| sulphates            | Sulfates (g/potassium sulfate/dmÂ³)    |
| alcohol              | Teneur en alcool (%)                  |
| quality              | Note de qualitÃ© (0â€“10)                |

---

## **2. Code Python utilisÃ©**

Le code complet dâ€™analyse statistique, tests de normalitÃ©, visualisations et ACP est repris ciâ€‘dessous :

```
# ======================================================
#   ANALYSE STATISTIQUE + ACP + VISUALISATIONS COMPLETES
# ======================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy.stats import shapiro

# ------------------------------------------------------
# 1) Charger la BDD
# ------------------------------------------------------
df = pd.read_csv("winequality-white.csv", sep=';')
print("\nAperÃ§u des donnÃ©es :")
print(df.head())

# ------------------------------------------------------
# 2) ANALYSE STATISTIQUE
# ------------------------------------------------------

print("\n===== STATISTIQUES DESCRIPTIVES =====")
print(df.describe().T)

# Valeurs manquantes
print("\n===== VALEURS MANQUANTES =====")
print(df.isnull().sum())

# ------------------------------------------------------
# 3) MATRICE DE CORRÃ‰LATION (GRAPHE)
# ------------------------------------------------------
plt.figure(figsize=(10,7))
sns.heatmap(df.corr(), cmap="coolwarm", annot=False)
plt.title("Heatmap de la matrice de corrÃ©lation")
plt.show()

# ------------------------------------------------------
# 4) DISTRIBUTION DES VARIABLES (HISTOGRAMMES)
# ------------------------------------------------------
df.hist(figsize=(14,10), bins=30)
plt.suptitle("Distribution des variables", fontsize=15)
plt.show()

# ------------------------------------------------------
# 5) BOXPLOTS (OUTLIERS)
# ------------------------------------------------------
plt.figure(figsize=(14,10))
for i, col in enumerate(df.columns):
    plt.subplot(4, 3, i+1)
    sns.boxplot(x=df[col])
    plt.title(col)
plt.tight_layout()
plt.show()

# ------------------------------------------------------
# 6) TEST DE NORMALITÃ‰ SHAPIRO-WILK
# ------------------------------------------------------
print("\n===== TEST SHAPIRO (NormalitÃ©) =====")
for col in df.columns:
    sample = df[col].sample(500, random_state=0)  # max pour Shapiro
    stat, p = shapiro(sample)
    print(f"{col}: p-value={p:.4f} -> {'Non normal' if p < 0.05 else 'Normal'}")

# ------------------------------------------------------
# 7) PREPARATION DES DONNÃ‰ES POUR Lâ€™ACP
# ------------------------------------------------------
X = df.drop(columns=['quality'])
y = df['quality']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ------------------------------------------------------
# 8) ACP
# ------------------------------------------------------
pca = PCA(n_components=5)
X_pca = pca.fit_transform(X_scaled)

explained_var = pca.explained_variance_ratio_
cum_var = np.cumsum(explained_var)

print("\n===== VARIANCE EXPLIQUÃ‰E =====")
for i, v in enumerate(explained_var, start=1):
    print(f"PC{i} : {v*100:.2f}%")

# -------------------------
# SCREE PLOT
# -------------------------
plt.figure(figsize=(7,5))
plt.plot(range(1, len(explained_var)+1), explained_var, marker='o')
plt.title("Scree plot - Variance expliquÃ©e")
plt.xlabel("Composante principale")
plt.ylabel("Variance expliquÃ©e")
plt.grid(True)
plt.show()

# -------------------------
# VARIANCE CUMULÃ‰E
# -------------------------
plt.figure(figsize=(7,5))
plt.plot(range(1, len(cum_var)+1), cum_var, marker='o')
plt.title("Variance expliquÃ©e cumulÃ©e")
plt.xlabel("Composantes")
plt.ylabel("Variance cumulÃ©e")
plt.grid(True)
plt.show()

# -------------------------
# PROJECTION PC1 vs PC2
# -------------------------
plt.figure(figsize=(8,6))
plt.scatter(X_pca[:,0], X_pca[:,1], c=y, cmap='viridis', alpha=0.7)
plt.colorbar(label="quality")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Projection ACP : PC1 vs PC2")
plt.grid(True)
plt.show()

# -------------------------
# BIPLOT (loadings + individus)
# -------------------------
loadings = pca.components_.T
features = X.columns

plt.figure(figsize=(8,6))
plt.scatter(X_pca[:,0], X_pca[:,1], alpha=0.4)

for i, var in enumerate(features):
    plt.arrow(0, 0, loadings[i,0]*3, loadings[i,1]*3, 
              color='red', head_width=0.05)
    plt.text(loadings[i,0]*3.2, loadings[i,1]*3.2, var, color='red')

plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Biplot ACP")
plt.axhline(0); plt.axvline(0)
plt.grid(True)
plt.show()

# -------------------------
# HEATMAP DES LOADINGS
# -------------------------
load_df = pd.DataFrame(loadings, index=features,
                       columns=[f"PC{i}" for i in range(1,6)])

plt.figure(figsize=(10,6))
sns.heatmap(load_df, annot=True, cmap="viridis")
plt.title("Loadings des variables sur les composantes principales")
plt.show()
```

---

## **3. RÃ©sultats & InterprÃ©tations dÃ©taillÃ©es**

### ### **3.1 Statistiques descriptives**
ML/Statistiques descriptives.png 

Le tableau `.describe()` montre :

* Certaines variables ont une **variabilitÃ© forte** (ex : sucre rÃ©siduel, soufre total).
* Dâ€™autres sont trÃ¨s concentrÃ©es autour dâ€™une faible plage (ex : pH, sulphates, chlorides).
* La qualitÃ© moyenne du vin est souvent autour de **5.8**, ce qui montre un dataset **dÃ©sÃ©quilibrÃ©** (peu de trÃ¨s bons/mauvais vins).

### **InterprÃ©tation :**

Les diffÃ©rences de dispersion indiquent que les variables influencent diffÃ©remment la qualitÃ© et devront Ãªtre standardisÃ©es avant lâ€™ACP.

---

## **3.2 Valeurs manquantes**

Aucune valeur manquante nâ€™a Ã©tÃ© dÃ©tectÃ©e (`0` partout). La base est propre et directement exploitable.

---

## **3.3 Matrice de corrÃ©lation â€“ Heatmap**

### **Principales corrÃ©lations observÃ©es :**

* **density â†— with residual sugar** : Le sucre influence logiquement la densitÃ© du vin.
* **alcohol â†˜ density** : Plus un vin contient dâ€™alcool, plus il est lÃ©ger.
* **free sulphur dioxide â†— total sulphur dioxide** : Relation mÃ©canique.

### **InterprÃ©tation :**

Aucune corrÃ©lation extrÃªme ne domine, ce qui signifie que les variables apportent des informations complÃ©mentaires, condition idÃ©ale pour une ACP.

---

## **3.4 Histogrammes des variables**

Les graphiques montrent :

* Plusieurs distributions **asymÃ©triques (skewed)** : sucre, chlorures, soufre.
* pH, aciditÃ© fixe et alcool prÃ©sentent des formes plus proches de distributions normales.

### **InterprÃ©tation :**

Les asymÃ©tries expliquent pourquoi le test de normalitÃ© conclura Ã  la nonâ€‘normalitÃ© pour la plupart des variables.

---

## **3.5 Boxplots â€” DÃ©tection des outliers**

Les boxplots rÃ©vÃ¨lent :

* Beaucoup dâ€™outliers dans : **residual sugar, chlorides, sulphates, SO2**, density.
* Peu dâ€™outliers pour pH et citric acid.

### **InterprÃ©tation :**

La production de vin peut naturellement gÃ©nÃ©rer des extrÃªmes : vins trÃ¨s sucrÃ©s, trÃ¨s sulfitÃ©es ou trÃ¨s alcoolisÃ©s.

---

## **3.6 Test de normalitÃ© â€” Shapiroâ€‘Wilk**

RÃ©sultat : quasi toutes les variables obtiennent **p-value < 0,05**, indiquant une **nonâ€‘normalitÃ©**.

### **InterprÃ©tation :**

Ceci confirme ce qui Ã©tait visible sur les histogrammes. Lâ€™ACP reste valable car elle ne nÃ©cessite pas la normalitÃ© des variables, seulement leur standardisation (ce qui est fait).

---

## **3.7 PrÃ©paration des donnÃ©es pour lâ€™ACP**

Les variables ont Ã©tÃ© standardisÃ©es avec `StandardScaler`, ce qui est indispensable Ã  cause des diffÃ©rences dâ€™Ã©chelles entre variables.

## **3.8 ACP â€” Analyse des composantes principales**

### **Variance expliquÃ©e**

Lâ€™ACP Ã  5 composantes montre :

* PC1 explique environ **30â€“40%** de la variance.
* PC1 + PC2 avoisinent **50â€“60%**.

### **Interpretation :**

La structure du dataset est relativement dispersÃ©e : aucune composante ne domine massivement. Les vins sont influencÃ©s par beaucoup de caractÃ©ristiques simultanÃ©es.

---

## **3.9 Scree Plot**

La courbe dÃ©croÃ®t progressivement sans cassure franche â†’ structure Â« diffuse Â».

**InterprÃ©tation :** lâ€™ACP ne rÃ©vÃ¨le pas de regroupements clairs de variables.

---

## **3.10 Projection PC1 vs PC2 (Individus)**

La projection colorÃ©e par la qualitÃ© montre :

* Les vins **plus alcoolisÃ©s et plus acides** se rapprochent du cÃ´tÃ© de PC1.
* Les vins **moins denses et plus qualitatifs** tendent Ã  se regrouper.

**InterprÃ©tation :**
Les dimensions principales reflÃ¨tent fortement :

* la teneur en alcool
* la densitÃ©
* les teneurs en soufre

---

## **3.11 Biplot (Individus + Variables)**

Le biplot montre :

* Les flÃ¨ches **alcohol**, **density**, **sugar** sont celles qui discriminent le plus.
* Des variables opposÃ©es indiquent des corrÃ©lations nÃ©gatives :

  * **alcohol â†” density**, par exemple.

**InterprÃ©tation :**
PC1 rÃ©sume une opposition entre vins lÃ©gers / alcoolisÃ©s et vins sucrÃ©s / denses.

---

## **3.12 Heatmap des loadings (coefficients de lâ€™ACP)**

Le tableau montre combien chaque variable contribue Ã  chaque composante.

### Observations clÃ©s :

* PC1 porte fortement sur **density** et **residual sugar**.
* PC2 porte sur **sulphates**, **chlorides** et **SO2**.
* Lâ€™alcool contribue Ã  PC1 et PC2.

---

# **Conclusion gÃ©nÃ©rale**

Lâ€™analyse statistique et lâ€™ACP montrent que :

* Le vin blanc est caractÃ©risÃ© par une grande diversitÃ© physicoâ€‘chimique.
* Les variables les plus discriminantes sont : **alcohol**, **density**, **residual sugar**, **SO2**.
* La qualitÃ© est modÃ©rÃ©ment corrÃ©lÃ©e Ã  lâ€™alcool et faiblement influencÃ©e par les autres caractÃ©ristiques.
* Lâ€™ACP permet de visualiser efficacement les structures globales mais la variabilitÃ© reste dispersÃ©e.

Vous disposez maintenant dâ€™un rapport complet incluant :
âœ” description de la BDD
âœ” code Python
âœ” analyses statistiques
enâœ” interprÃ©tations approfondies de chaque graphique.
